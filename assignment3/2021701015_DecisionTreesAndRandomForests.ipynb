{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0_wToNFHMN3"
   },
   "source": [
    "# **Decision Trees**\n",
    "\n",
    "The Wisconsin Breast Cancer Dataset(WBCD) can be found here(https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data)\n",
    "\n",
    "This dataset describes the characteristics of the cell nuclei of various patients with and without breast cancer. The task is to classify a decision tree to predict if a patient has a benign or a malignant tumour based on these features.\n",
    "\n",
    "Attribute Information:\n",
    "```\n",
    "#  Attribute                     Domain\n",
    "   -- -----------------------------------------\n",
    "   1. Sample code number            id number\n",
    "   2. Clump Thickness               1 - 10\n",
    "   3. Uniformity of Cell Size       1 - 10\n",
    "   4. Uniformity of Cell Shape      1 - 10\n",
    "   5. Marginal Adhesion             1 - 10\n",
    "   6. Single Epithelial Cell Size   1 - 10\n",
    "   7. Bare Nuclei                   1 - 10\n",
    "   8. Bland Chromatin               1 - 10\n",
    "   9. Normal Nucleoli               1 - 10\n",
    "  10. Mitoses                       1 - 10\n",
    "  11. Class:                        (2 for benign, 4 for malignant)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qYdlWpUVHMOB"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CT</th>\n",
       "      <th>UCSize</th>\n",
       "      <th>UCShape</th>\n",
       "      <th>MA</th>\n",
       "      <th>SECSize</th>\n",
       "      <th>BN</th>\n",
       "      <th>BC</th>\n",
       "      <th>NN</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.417740</td>\n",
       "      <td>3.134478</td>\n",
       "      <td>3.207439</td>\n",
       "      <td>2.806867</td>\n",
       "      <td>3.216023</td>\n",
       "      <td>3.463519</td>\n",
       "      <td>3.437768</td>\n",
       "      <td>2.866953</td>\n",
       "      <td>1.589413</td>\n",
       "      <td>2.689557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.815741</td>\n",
       "      <td>3.051459</td>\n",
       "      <td>2.971913</td>\n",
       "      <td>2.855379</td>\n",
       "      <td>2.214300</td>\n",
       "      <td>3.640708</td>\n",
       "      <td>2.438364</td>\n",
       "      <td>3.053634</td>\n",
       "      <td>1.715078</td>\n",
       "      <td>0.951273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CT      UCSize     UCShape          MA     SECSize          BN  \\\n",
       "count  699.000000  699.000000  699.000000  699.000000  699.000000  699.000000   \n",
       "mean     4.417740    3.134478    3.207439    2.806867    3.216023    3.463519   \n",
       "std      2.815741    3.051459    2.971913    2.855379    2.214300    3.640708   \n",
       "min      1.000000    1.000000    1.000000    1.000000    1.000000    0.000000   \n",
       "25%      2.000000    1.000000    1.000000    1.000000    2.000000    1.000000   \n",
       "50%      4.000000    1.000000    1.000000    1.000000    2.000000    1.000000   \n",
       "75%      6.000000    5.000000    5.000000    4.000000    4.000000    5.000000   \n",
       "max     10.000000   10.000000   10.000000   10.000000   10.000000   10.000000   \n",
       "\n",
       "               BC          NN     Mitoses   Diagnosis  \n",
       "count  699.000000  699.000000  699.000000  699.000000  \n",
       "mean     3.437768    2.866953    1.589413    2.689557  \n",
       "std      2.438364    3.053634    1.715078    0.951273  \n",
       "min      1.000000    1.000000    1.000000    2.000000  \n",
       "25%      2.000000    1.000000    1.000000    2.000000  \n",
       "50%      3.000000    1.000000    1.000000    2.000000  \n",
       "75%      5.000000    4.000000    1.000000    4.000000  \n",
       "max     10.000000   10.000000   10.000000    4.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "headers = [\"ID\",\"CT\",\"UCSize\",\"UCShape\",\"MA\",\"SECSize\",\"BN\",\"BC\",\"NN\",\"Mitoses\",\"Diagnosis\"]\n",
    "data = pd.read_csv('breast-cancer-wisconsin.data', na_values='?',    \n",
    "         header=None, index_col=['ID'], names = headers) \n",
    "data = data.reset_index(drop=True)\n",
    "data = data.fillna(0)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_gQq5qrHMOG"
   },
   "source": [
    "1. a) Implement a decision tree (you can use decision tree implementation from existing libraries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "g6R3GmzBHMOH"
   },
   "outputs": [],
   "source": [
    "input_features = (list(data.columns[:9]))\n",
    "X = data[input_features]\n",
    "y = data.Diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(699, 9)\n",
      "(699,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(489, 9) (489,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZ7N9m_mHMOJ"
   },
   "source": [
    "1. b) Train a decision tree object of the above class on the WBC dataset using misclassification rate, entropy and Gini as the splitting metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf0 = DecisionTreeClassifier()\n",
    "clf0.fit(X_train, y_train)\n",
    "prediction0 = clf0.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "eHFij6PaHMOJ"
   },
   "outputs": [],
   "source": [
    "#Gini\n",
    "clf1 = DecisionTreeClassifier(criterion='gini')\n",
    "clf1.fit(X_train, y_train)\n",
    "prediction1 = clf1.predict(X_test)\n",
    "\n",
    "#Entropy\n",
    "clf2 = DecisionTreeClassifier(criterion='entropy')\n",
    "clf2.fit(X_train, y_train)\n",
    "prediction2 = clf2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXEjInvmHMOK"
   },
   "source": [
    "1. c) Report the accuracies in each of the above splitting metrics and give the best result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "49QZvmgNHMOL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using Miss classification rate is:  0.9380952380952381\n",
      "Accuracy using Gini index is:  0.9333333333333333\n",
      "Accuracy using Entropy is:  0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of misclassification rate\n",
    "print(\"Accuracy using Miss classification rate is: \", metrics.accuracy_score(prediction0, y_test))\n",
    "\n",
    "# Accuracy of gini\n",
    "print(\"Accuracy using Gini index is: \", metrics.accuracy_score(prediction1, y_test))\n",
    "\n",
    "# Accuracy by entropy\n",
    "print(\"Accuracy using Entropy is: \", metrics.accuracy_score(prediction2, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bz_7nYxPHMON"
   },
   "source": [
    "1. d) Experiment with different approaches to decide when to terminate the tree (number of layers, purity measure, etc). Report and give explanations for all approaches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "yLRI0niJHMOP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with max-depth=7 and minimum sample split=3:  0.9428571428571428\n",
      "Accuracy with max-depth=7 and minimum sample split=3:  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "Dec1 = DecisionTreeClassifier(criterion='entropy', max_depth=7, min_samples_split = 3)\n",
    "Dec1.fit(X_train, y_train)\n",
    "Pred1 = Dec1.predict(X_test)\n",
    "\n",
    "print(\"Accuracy with max-depth=7 and minimum sample split=3: \", metrics.accuracy_score(Pred1, y_test))\n",
    "\n",
    "Dec2 = DecisionTreeClassifier(max_depth=4, min_samples_split = 0.2)\n",
    "Dec2.fit(X_train, y_train)\n",
    "Pred2 = Dec2.predict(X_test)\n",
    "\n",
    "print(\"Accuracy with max-depth=7 and minimum sample split=3: \", metrics.accuracy_score(Pred2, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWAN_wWXHMOQ"
   },
   "source": [
    "2. What is boosting, bagging and  stacking?\n",
    "Which class does random forests belong to and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LnO5uqHlHMOR"
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "#### Boosting: \n",
    "It is one of the ensemble techniques in which combination of weak classifier results into strong classifier. First weak models are built in a series. Sequential building of models takes place such that, one model tried to improve or correct the errors made by the other models. To the end all the weak models are combined to get the final model.\n",
    "\n",
    "#### Bagging: \n",
    "In bagging, Several weak algorithms are trained independent and parallel to each other after which they are combined together using averaging techniques.\n",
    "\n",
    "#### Stacking: \n",
    "In stacking, initially several separate weak models are trained parallely. After training these models separately, they are combined using another model called meta-model which is based on the different weak model's outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest:\n",
    "This algorithm belongs to **Bagging** because it learns the trees in parallel to each other and the most common output i.e similar output is selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pihvGbqLHMOS"
   },
   "source": [
    "3. Implement random forest algorithm using different decision trees . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data.keys()\n",
    "features = ['CT', 'UCSize', 'UCShape', 'MA', 'SECSize', 'BN', 'BC', 'NN', 'Mitoses']\n",
    "X = np.array(data[features])\n",
    "Y = np.array(data.Diagnosis)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "dXdPP2aIHMOT"
   },
   "outputs": [],
   "source": [
    "def create_trees(X_train, Y_train, criterion=\"entropy\", max_depth=8, min_size=5, n_features=3):\n",
    "\n",
    "    Dec = DecisionTreeClassifier(criterion=criterion, max_depth=max_depth, min_samples_split = min_size, max_features=n_features)\n",
    "    Dec.fit(X_train, Y_train)\n",
    "    return Dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_list = list(range(2,20))\n",
    "criterion_list = [\"gini\", \"entropy\"]\n",
    "min_size_list = list(range(2,10))\n",
    "n_features_list = list(range(3,X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 210)\n",
      "(210,)\n"
     ]
    }
   ],
   "source": [
    "n_trees = 6\n",
    "max_rows = X_train.shape[0]\n",
    "\n",
    "all_preds = []\n",
    "\n",
    "for i in range(1000):\n",
    "  \n",
    "  ids = np.random.randint(max_rows, size=(int(.7*max_rows)))\n",
    "  X_train_split = []\n",
    "  Y_train_split = []\n",
    "  \n",
    "  for i in ids:\n",
    "\n",
    "    X_train_split.append(X_train[i])\n",
    "    Y_train_split.append(Y_train[i])\n",
    "\n",
    "  X_train_split = np.array(X_train_split)\n",
    "  Y_train_split = np.array(Y_train_split)\n",
    "\n",
    "  id_max_depth = np.random.randint(len(max_depth_list),size=1)[0]\n",
    "  id_criterion = np.random.randint(len(criterion_list),size=1)[0]\n",
    "  id_min_size = np.random.randint(len(min_size_list),size=1)[0]\n",
    "  id_feature = np.random.randint(len(n_features_list),size=1)[0]\n",
    "\n",
    "  tree = create_trees(X_train_split, Y_train_split, criterion_list[id_criterion], max_depth_list[id_max_depth], min_size_list[id_min_size], n_features_list[id_feature])\n",
    "\n",
    "  all_preds.append(tree.predict(X_test))\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "Y_pred = []\n",
    "for i in range(all_preds.shape[1]):\n",
    "  temp = all_preds[:,i]\n",
    "  counts = np.bincount(temp)\n",
    "  Y_pred.append(np.argmax(counts))\n",
    "Y_pred = np.array(Y_pred)\n",
    "print(all_preds.shape)\n",
    "print(Y_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJOn5nNZHMOU"
   },
   "source": [
    "4. Report the accuracies obtained after using the Random forest algorithm and compare it with the best accuracies obtained with the decision trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Ce4KiiIGHMOV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy from Decision Trees:  93.33333333333333\n",
      "Best Accuracy from Random Forest is:  95.23809523809523\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Accuracy from Decision Trees: \", (metrics.accuracy_score(prediction1, y_test))*100)\n",
    "print(\"Best Accuracy from Random Forest is: \", (metrics.accuracy_score(Y_pred, Y_test))*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, it can be seen that Random forest performs better than decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yj-vNvsYHMOX"
   },
   "source": [
    "5. Submit your solution as a separate pdf in the final zip file of your submission\n",
    "\n",
    "\n",
    "Compute a decision tree with the goal to predict the food review based on its smell, taste and portion size.\n",
    "\n",
    "(a) Compute the entropy of each rule in the first stage.\n",
    "\n",
    "(b) Show the final decision tree. Clearly draw it.\n",
    "\n",
    "Submit a handwritten response. Clearly show all the steps.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Decision_trees.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "1f8d80d535cfd832283e4e3a1095d2ce45fe6627336684f2622a1965babb2f1c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
